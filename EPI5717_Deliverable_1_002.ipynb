{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo2n25AUJmn9"
      },
      "source": [
        "# MIMIC-IV-ED Dataset\n",
        "\n",
        "## Descrição\n",
        "MIMIC-IV-ED is a large, freely available database of emergency department (ED) admissions at the Beth Israel Deaconess Medical Center between 2011 and 2019. The database contains ~425,000 ED stays. Vital signs, triage information, medication reconciliation, medication administration, and discharge diagnoses are available. All data are deidentified to comply with the Health Information Portability and Accountability Act (HIPAA) Safe Harbor provision. MIMIC-IV-ED is intended to support a diverse range of education initiatives and research studies.\n",
        "\n",
        "## Plano\n",
        "Utilizar dados disponíveis logo após a avaliação na triagem para prever se o paciente será internado no hospital ou não. As informações que estarão disponíveis neste momento são:\n",
        "- raça\n",
        "- gênero\n",
        "- idade\n",
        "- o meio pelo qual o paciente chegou ao hospital\n",
        "- data e hora da entrada no hospital\n",
        "- medicamentos em uso até antes da visita ao serviço de emergência\n",
        "  - National Drug Code (NDC): O NDC, ou Código Nacional de Medicamentos, é um número único de 10 dígitos e 3 segmentos. É um identificador universal de produto para medicamentos humanos nos Estados Unidos. O código está presente em todas as embalagens e bulas de medicamentos sem receita (OTC) e com receita nos EUA.\n",
        "  - Grupo ontológico\n",
        "  Atenção: Note que como um medicamento pode ser classificado em múltiplos grupos na ontologia, pode haver mais de uma linha para um único medicamento. Por exemplo, o medicamento Adderall é (1) um estimulante do SNC, (2) uma terapia para Transtorno de Déficit de Atenção e Hiperatividade, e (3) uma terapia para narcolepsia.\n",
        "\n",
        "- sinais vitais e outras avaliações objetivas, incluindo:\n",
        "  - temperatura\n",
        "  - frequência cardíaca\n",
        "  - frequência respiratória\n",
        "  - saturação de O2\n",
        "  - pressão arterial sistólica\n",
        "  - pressão arterial diastólica\n",
        "- nível de urgência, que é um número de 1 a 5 representando o nível de urgência do caso com base na impressão do profissional que executou a triagem. 1 representa a maior gravidade e 5 a menor gravidade.\n",
        "\n",
        "Cada uma dessas vai virar uma proporção de admissão, e será selecionada a máxima, a média, a mínima, desvio-padrão. As proporções de admissão devem ser baseadas somente nos dados selecionados para treino.\n",
        "\n",
        "Modelos de machine learning para testar e otimizar para a tarefa:\n",
        "- Random Forest\n",
        "- XGBoost\n",
        "- Light GBM\n",
        "- GBM\n",
        "- GLM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5Lar4HMNjI"
      },
      "source": [
        "## Trabalhos anteriores\n",
        "\n",
        "---\n",
        "\n",
        "**A Machine Learning Pipeline Using KNIME to Predict Hospital Admission in the MIMIC-IV Database**\n",
        "\n",
        "**Abstract:**\n",
        "It is well known that overcrowding in emergency department (ED) lowers the standard of care and raises the risk of medical errors. An initial predictive supplementary tool of hospital admission at an early stage of a patient's arrival to the emergency department (ED) can provide health care professionals a number of advantages, such as, more efficient patient flow management and better hospital care. In this paper, we use data from the Medical Information Mart for Intensive Care IV Emergency Department (MIMIC-IV-ED) database to predict whether a patient will be admitted to the hospital or not. The choice of predictive attributes was driven by simplicity (a set of basic vital signs were used) so that the prediction can be made at an early stage of the patient's arrival. Several versions of Machine Learning (ML) algorithms based on Decision Trees (DT) were used for classification and prediction. An important asset of the proposed methodology is that the whole process is implemented through an ML pipeline created with an open-source, visual programming tool. The proposed methodology contains the pre-processing stage, the modelling stage includes seven classifiers, and the combined visualization of the evaluation of the predictive models. The Gradient Boosted Trees method outperforms the rest of the algorithms that were used. An accuracy of 80% can be achieved only by using early triage data.\n",
        "\n",
        "**URL:** https://ieeexplore.ieee.org/document/10345903\n",
        "\n",
        "---\n",
        "**Machine Learning in Medical Triage: A Predictive Model for Emergency Department Disposition**\n",
        "\n",
        "**Abstract:**\n",
        "The study explores the application of automated machine learning (AutoML) using the MIMIC-IV-ED database to enhance decision-making in emergency department (ED) triage. We developed a predictive model that utilizes triage data to forecast hospital admissions, aiming to support medical staff by providing an advanced decision-support system. The model, powered by H2O.ai’s AutoML platform, was trained on approximately 280,000 preprocessed records from the Beth Israel Deaconess Medical Center collected between 2011 and 2019. The selected Gradient Boosting Machine (GBM) model demonstrated an AUC ROC of 0.8256, indicating its efficacy in predicting patient dispositions. Key variables such as acuity and waiting hours were identified as significant predictors, emphasizing the model’s capability to integrate critical triage metrics into its predictions. However, challenges related to the complexity and heterogeneity of medical data, privacy concerns, and the need for model interpretability were addressed through the incorporation of Explainable AI (XAI) techniques. These techniques ensure the transparency of the predictive processes, fostering trust and facilitating ethical AI use in clinical settings. Future work will focus on external validation and expanding the model to include a broader array of variables from diverse healthcare environments, enhancing the model’s utility and applicability in global emergency care contexts.\n",
        "\n",
        "**URL:** https://www.mdpi.com/2076-3417/14/15/6623\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zQwUJWrptJAx"
      },
      "outputs": [],
      "source": [
        "# %load_ext cudf.pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wu2CDaIkm5gk"
      },
      "outputs": [],
      "source": [
        "# !wget -r -N -c -np --user almeidava93 --password physionet@aL134921365 https://physionet.org/files/mimic-iv-ed/2.2/ -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L2elZE86zcJZ"
      },
      "outputs": [],
      "source": [
        "# !wget -r -N -c -np --user almeidava93 --password physionet@aL134921365 https://physionet.org/files/mimiciv/3.0/hosp/patients.csv.gz -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZoK-Ph3LJUr",
        "outputId": "1ef9e318-5666-4ebe-f9f2-5fd68cd56376"
      },
      "outputs": [],
      "source": [
        "# Após download de arquivos comprimidos em .gz, descomprimir para ter acesso aos csv\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "cwd = Path(os.getcwd())\n",
        "\n",
        "for (root,dirs,files) in os.walk(cwd/'physionet.org'):\n",
        "  for file in files:\n",
        "    if file.endswith('.gz'):\n",
        "      compressed_file_path = Path(root, file)\n",
        "      decompressed_file_path = Path(root, file[:-3])\n",
        "\n",
        "      with gzip.open(compressed_file_path, 'rb') as f1:\n",
        "        with open(decompressed_file_path, 'wb') as f2:\n",
        "          shutil.copyfileobj(f1, f2)\n",
        "\n",
        "      os.remove(compressed_file_path)\n",
        "      print(f\"File {decompressed_file_path} decompressed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Or7haVDdOSPM"
      },
      "outputs": [],
      "source": [
        "# Carregar DataFrames com todas as tabelas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "edstays_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/edstays.csv')\n",
        "edstays_df = pd.read_csv(edstays_path)\n",
        "\n",
        "diagnosis_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/diagnosis.csv')\n",
        "diagnosis_df = pd.read_csv(diagnosis_path)\n",
        "\n",
        "medrecon_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/medrecon.csv')\n",
        "medrecon_df = pd.read_csv(medrecon_path)\n",
        "\n",
        "pyxis_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/pyxis.csv')\n",
        "pyxis_df = pd.read_csv(pyxis_path)\n",
        "\n",
        "triage_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/triage.csv')\n",
        "triage_df = pd.read_csv(triage_path)\n",
        "\n",
        "vitalsign_path = Path('physionet.org/files/mimic-iv-ed/2.2/ed/vitalsign.csv')\n",
        "vitalsign_df = pd.read_csv(vitalsign_path)\n",
        "\n",
        "patients_path = Path('physionet.org/files/mimiciv/3.0/hosp/patients.csv')\n",
        "patients_df = pd.read_csv(patients_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hQ8wVrzR1VLz",
        "outputId": "5241c284-e2d6-44d0-b4c2-d2cd07ce120b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>stay_id</th>\n",
              "      <th>intime</th>\n",
              "      <th>outtime</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "      <th>arrival_transport</th>\n",
              "      <th>disposition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000032</td>\n",
              "      <td>22595853.0</td>\n",
              "      <td>33258284</td>\n",
              "      <td>2180-05-06 19:17:00</td>\n",
              "      <td>2180-05-06 23:30:00</td>\n",
              "      <td>F</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>AMBULANCE</td>\n",
              "      <td>ADMITTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000032</td>\n",
              "      <td>22841357.0</td>\n",
              "      <td>38112554</td>\n",
              "      <td>2180-06-26 15:54:00</td>\n",
              "      <td>2180-06-26 21:31:00</td>\n",
              "      <td>F</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>AMBULANCE</td>\n",
              "      <td>ADMITTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000032</td>\n",
              "      <td>25742920.0</td>\n",
              "      <td>35968195</td>\n",
              "      <td>2180-08-05 20:58:00</td>\n",
              "      <td>2180-08-06 01:44:00</td>\n",
              "      <td>F</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>AMBULANCE</td>\n",
              "      <td>ADMITTED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10000032</td>\n",
              "      <td>29079034.0</td>\n",
              "      <td>32952584</td>\n",
              "      <td>2180-07-22 16:24:00</td>\n",
              "      <td>2180-07-23 05:54:00</td>\n",
              "      <td>F</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>AMBULANCE</td>\n",
              "      <td>HOME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10000032</td>\n",
              "      <td>29079034.0</td>\n",
              "      <td>39399961</td>\n",
              "      <td>2180-07-23 05:54:00</td>\n",
              "      <td>2180-07-23 14:00:00</td>\n",
              "      <td>F</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>AMBULANCE</td>\n",
              "      <td>ADMITTED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subject_id     hadm_id   stay_id               intime              outtime  \\\n",
              "0    10000032  22595853.0  33258284  2180-05-06 19:17:00  2180-05-06 23:30:00   \n",
              "1    10000032  22841357.0  38112554  2180-06-26 15:54:00  2180-06-26 21:31:00   \n",
              "2    10000032  25742920.0  35968195  2180-08-05 20:58:00  2180-08-06 01:44:00   \n",
              "3    10000032  29079034.0  32952584  2180-07-22 16:24:00  2180-07-23 05:54:00   \n",
              "4    10000032  29079034.0  39399961  2180-07-23 05:54:00  2180-07-23 14:00:00   \n",
              "\n",
              "  gender   race arrival_transport disposition  \n",
              "0      F  WHITE         AMBULANCE    ADMITTED  \n",
              "1      F  WHITE         AMBULANCE    ADMITTED  \n",
              "2      F  WHITE         AMBULANCE    ADMITTED  \n",
              "3      F  WHITE         AMBULANCE        HOME  \n",
              "4      F  WHITE         AMBULANCE    ADMITTED  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edstays_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oD3z85Eu1Gow",
        "outputId": "ce05bcb4-2715-46f7-829e-b1040c24a0c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>anchor_age</th>\n",
              "      <th>anchor_year</th>\n",
              "      <th>anchor_year_group</th>\n",
              "      <th>dod</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000032</td>\n",
              "      <td>F</td>\n",
              "      <td>52</td>\n",
              "      <td>2180</td>\n",
              "      <td>2014 - 2016</td>\n",
              "      <td>2180-09-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000048</td>\n",
              "      <td>F</td>\n",
              "      <td>23</td>\n",
              "      <td>2126</td>\n",
              "      <td>2008 - 2010</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10000058</td>\n",
              "      <td>F</td>\n",
              "      <td>33</td>\n",
              "      <td>2168</td>\n",
              "      <td>2020 - 2022</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10000068</td>\n",
              "      <td>F</td>\n",
              "      <td>19</td>\n",
              "      <td>2160</td>\n",
              "      <td>2008 - 2010</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10000084</td>\n",
              "      <td>M</td>\n",
              "      <td>72</td>\n",
              "      <td>2160</td>\n",
              "      <td>2017 - 2019</td>\n",
              "      <td>2161-02-13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   subject_id gender  anchor_age  anchor_year anchor_year_group         dod\n",
              "0    10000032      F          52         2180       2014 - 2016  2180-09-09\n",
              "1    10000048      F          23         2126       2008 - 2010         NaN\n",
              "2    10000058      F          33         2168       2020 - 2022         NaN\n",
              "3    10000068      F          19         2160       2008 - 2010         NaN\n",
              "4    10000084      M          72         2160       2017 - 2019  2161-02-13"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "patients_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vDKeyQvmUAtK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Vinicius\\AppData\\Local\\Temp\\ipykernel_26164\\2926409353.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  triage_data_df['pain'] = triage_data_df['pain'].apply(convert_to_int)\n"
          ]
        }
      ],
      "source": [
        "# Organizar DataFrame único com dados de interesse\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "data_df = pd.DataFrame()\n",
        "data_df[\"id\"] = edstays_df[\"stay_id\"]\n",
        "data_df[\"subject_id\"] = edstays_df[\"subject_id\"]\n",
        "\n",
        "# Codificar dados categóricos\n",
        "## Selecionar variáveis categóricas\n",
        "data_df[\"gender\"] = edstays_df[\"gender\"]\n",
        "data_df[\"race\"] = edstays_df[\"race\"]\n",
        "data_df[\"arrival_transport\"] = edstays_df[\"arrival_transport\"]\n",
        "categoric_cols = [\"gender\", \"race\", \"arrival_transport\"]\n",
        "## Criar one-hot encoding de variáveis categóricas\n",
        "data_df = pd.get_dummies(data_df, columns=categoric_cols)\n",
        "\n",
        "# Incluir informações sobre a hora, o dia da semana e o mês do ano em que a visita ao serviço de emergência ocorreu\n",
        "data_df['intime'] = pd.to_datetime(edstays_df['intime'])\n",
        "data_df['in_day_of_the_week'] = data_df['intime'].dt.day_of_week\n",
        "data_df['in_hour_of_the_day'] = data_df['intime'].dt.hour\n",
        "data_df['in_month_of_the_year'] = data_df['intime'].dt.month\n",
        "\n",
        "# Circular encoding - Padronizar dados cíclicos para representar melhor a ciclicidade presente no dado\n",
        "## Selecionar variáveis cíclicas\n",
        "cyclic_cols = ['in_day_of_the_week', 'in_hour_of_the_day', 'in_month_of_the_year']\n",
        "## Realizar circular encoding para cada variável\n",
        "for col in cyclic_cols:\n",
        "  data_df[f'{col}_sin'] = np.sin(2 * np.pi * data_df[col] / len(data_df[col].unique()))\n",
        "  data_df[f'{col}_cos'] = np.cos(2 * np.pi * data_df[col] / len(data_df[col].unique()))\n",
        "## Deletar colunas originais\n",
        "data_df.drop(columns=cyclic_cols, inplace=True)\n",
        "\n",
        "# Incluir se o paciente foi admitido ao hospital ou não\n",
        "data_df['admitted_to_hosp'] = edstays_df['hadm_id'].apply(lambda x: np.isnan(x)==False).astype(int)\n",
        "\n",
        "# Incluir dados coletados na triagem do hospital\n",
        "## Seleção das variáveis relevantes\n",
        "triage_data_df = triage_df[['stay_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'acuity', 'pain']]\n",
        "\n",
        "## Conversão dos dados da coluna pain para dado numérico inteiro quando possível. Se não é possível, deixar como missing.\n",
        "def convert_to_int(value):\n",
        "    try:\n",
        "        return int(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "    \n",
        "triage_data_df['pain'] = triage_data_df['pain'].apply(convert_to_int)\n",
        "\n",
        "## União das tabelas\n",
        "data_df = pd.merge(data_df, triage_data_df, left_on='id', right_on='stay_id', how='left')\n",
        "\n",
        "# Incluir dado de idade do paciente ('anchor_age')\n",
        "patients_age_df = patients_df[['subject_id', 'anchor_age']]\n",
        "## União das tabelas através do id do paciente\n",
        "data_df = pd.merge(data_df, patients_age_df, left_on='subject_id', right_on='subject_id', how='left')\n",
        "\n",
        "# Tratar dados faltantes\n",
        "## Criar coluna com one-hot encoding definindo se existe valor faltando ou não para aquela variável\n",
        "cols_with_missing_values = []\n",
        "for col in data_df.columns:\n",
        "  if data_df[col].isna().any():\n",
        "    cols_with_missing_values.append(col)\n",
        "    data_df[f'{col}_is_missing'] = data_df[col].isna().astype(int)\n",
        "\n",
        "# Reunir dados relativos os medicamentos que os pacientes faziam uso até antes de passarem na emergência\n",
        "# Reunir por cada código disponível, que considera princípio ativo e grupo de medicamentos\n",
        "# Pegar lista de códigos NDC (National Drug Code) de medicamentos e associar a cada stay_id\n",
        "med_by_stay_id_ndc = medrecon_df.groupby('stay_id')['ndc'].unique()\n",
        "data_df = pd.merge(data_df, med_by_stay_id_ndc, left_on='id', right_on='stay_id', how='left')\n",
        "\n",
        "# Pegar lista de códigos etccode de medicamentos e associar a cada stay_id\n",
        "med_by_stay_id_etccode = medrecon_df.groupby('stay_id')['etccode'].unique()\n",
        "data_df = pd.merge(data_df, med_by_stay_id_etccode, left_on='id', right_on='stay_id', how='left')\n",
        "\n",
        "# Pegar lista de códigos Generic Sequence Number (GSN) de medicamentos e associar a cada stay_id\n",
        "med_by_stay_id_gsn = medrecon_df.groupby('stay_id')['gsn'].unique()\n",
        "data_df = pd.merge(data_df, med_by_stay_id_gsn, left_on='id', right_on='stay_id', how='left')\n",
        "\n",
        "# Pegar lista nomes de medicamentos e associar a cada stay_id\n",
        "med_by_stay_id_name = medrecon_df.groupby('stay_id')['name'].unique()\n",
        "data_df = pd.merge(data_df, med_by_stay_id_name, left_on='id', right_on='stay_id', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Incluir número de medicamentos que o paciente usava antes da passagem na emergência\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_len(list):\n",
        "    if list is np.nan:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(list)\n",
        "\n",
        "# Pegar o número de medicamentos segundo códigos NDC únicos \n",
        "data_df['med_count_by_ndc'] = data_df['ndc'].apply(get_len)\n",
        "# Pegar o número de medicamentos segundo códigos ETC únicos \n",
        "data_df['med_count_by_etccode'] = data_df['etccode'].apply(get_len)\n",
        "# Pegar o número de medicamentos segundo nomes únicos de medicamentos \n",
        "data_df['med_count_by_name'] = data_df['name'].apply(get_len)\n",
        "# Pegar o número de medicamentos segundo códigos GSN únicos \n",
        "data_df['med_count_by_gsn'] = data_df['gsn'].apply(get_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar coluna enfatizando o fato de o paciente não usar nenhuma medicação continuamente até o momento da passagem na emergência\n",
        "data_df['use_no_medication'] = data_df['med_count_by_ndc']==0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VghBk79w2-dC"
      },
      "outputs": [],
      "source": [
        "# Preparar datasets\n",
        "random_state = 42\n",
        "## Separar variáveis preditoras da variável a ser predita\n",
        "X = data_df.drop('admitted_to_hosp', axis=1)\n",
        "y = data_df['admitted_to_hosp']\n",
        "## Separar em dataset de treino (90%) e teste (10%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)\n",
        "## Separar dados de treino em treino (90%) e validação (10%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qY9fugF6oDR"
      },
      "source": [
        "### Target encoding de medicamentos\n",
        "Proporções de internações calculadas com base em:\n",
        "- códigos NDC\n",
        "- códigos ETC\n",
        "- nomes de medicamentos\n",
        "- códigos GSN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-yZ5S14E3kfc"
      },
      "outputs": [],
      "source": [
        "# Separar dados de medicamentos para target encoding utilizando dados do dataset de treino\n",
        "medrecon_train_df = medrecon_df[medrecon_df[\"stay_id\"].isin(X_train[\"id\"])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUb4RHFKRxT2"
      },
      "source": [
        "#### Proporção de admissões por código NDC de medicamentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "72b_VC6jR4ob"
      },
      "outputs": [],
      "source": [
        "# Agrupar medicamentos por código NDC presentes no dataset de treino e as passagens na emergência\n",
        "med_adm_prop_by_ndc = medrecon_train_df.groupby('ndc')['stay_id'].unique().reset_index()\n",
        "\n",
        "# Calcular a proporção das passagens na emergência em que havia uso do medicamento com um nome específico e que terminaram em admissão hospitalar\n",
        "med_adm_prop_by_ndc['admission_proportion_by_ndc'] = med_adm_prop_by_ndc['stay_id'].apply(\n",
        "    lambda stay_ids: edstays_df[edstays_df[\"stay_id\"].isin(stay_ids)]['hadm_id'].notna().mean()\n",
        ")\n",
        "# med_adm_prop_by_ndc é a referência para a proporção de admissão relacionada a cada medicamento\n",
        "med_adm_prop_by_ndc.drop(columns=['stay_id'], inplace=True)\n",
        "\n",
        "# Usar chance de admissão geral dos dados de treino caso não haja medicamentos em uso com código NDC\n",
        "general_admission_proportion = y_train.value_counts(normalize=True).iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos NDC.\n",
        "def estimate_max_admission_proportion_by_ndc(ndc_list):\n",
        "  if ndc_list is None or ndc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao de maior chance de internação\n",
        "  return med_adm_prop_by_ndc[med_adm_prop_by_ndc['ndc'].isin(ndc_list)]['admission_proportion_by_ndc'].max()\n",
        "\n",
        "X_train['ndc_max_adm_prop'] = X_train['ndc'].apply(estimate_max_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_val['ndc_max_adm_prop'] = X_val['ndc'].apply(estimate_max_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_test['ndc_max_adm_prop'] = X_test['ndc'].apply(estimate_max_admission_proportion_by_ndc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos NDC.\n",
        "def estimate_mean_admission_proportion_by_ndc(ndc_list):\n",
        "  if ndc_list is None or ndc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente à média das chances de internação de cada medicamento\n",
        "  return med_adm_prop_by_ndc[med_adm_prop_by_ndc['ndc'].isin(ndc_list)]['admission_proportion_by_ndc'].mean()\n",
        "\n",
        "X_train['ndc_mean_adm_prop'] = X_train['ndc'].apply(estimate_mean_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_val['ndc_mean_adm_prop'] = X_val['ndc'].apply(estimate_mean_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_test['ndc_mean_adm_prop'] = X_test['ndc'].apply(estimate_mean_admission_proportion_by_ndc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos NDC.\n",
        "def estimate_min_admission_proportion_by_ndc(ndc_list):\n",
        "  if ndc_list is None or ndc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor mínimo das chances de internação de cada medicamento\n",
        "  return med_adm_prop_by_ndc[med_adm_prop_by_ndc['ndc'].isin(ndc_list)]['admission_proportion_by_ndc'].min()\n",
        "\n",
        "X_train['ndc_min_adm_prop'] = X_train['ndc'].apply(estimate_min_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_val['ndc_min_adm_prop'] = X_val['ndc'].apply(estimate_min_admission_proportion_by_ndc).fillna(general_admission_proportion)\n",
        "X_test['ndc_min_adm_prop'] = X_test['ndc'].apply(estimate_min_admission_proportion_by_ndc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfpePBUySmEK"
      },
      "source": [
        "#### Proporção de admissões por código ETC de medicamentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QSZFSVS_StBv"
      },
      "outputs": [],
      "source": [
        "# Agrupar medicamentos por código etc presentes no dataset de treino e as passagens na emergência\n",
        "med_adm_prop_by_etc = medrecon_train_df.groupby('etccode')['stay_id'].unique().reset_index()\n",
        "\n",
        "# Calcular a proporção das passagens na emergência em que havia uso do medicamento com um nome específico e que terminaram em admissão hospitalar\n",
        "med_adm_prop_by_etc['admission_proportion_by_etc'] = med_adm_prop_by_etc['stay_id'].apply(\n",
        "    lambda stay_ids: edstays_df[edstays_df[\"stay_id\"].isin(stay_ids)]['hadm_id'].notna().mean()\n",
        ")\n",
        "# med_adm_prop_by_etc é a referência para a proporção de admissão relacionada a cada medicamento\n",
        "med_adm_prop_by_etc.drop(columns=['stay_id'], inplace=True)\n",
        "\n",
        "# Usar chance de admissão geral dos dados de treino caso não haja medicamentos em uso com código etc\n",
        "general_admission_proportion = y_train.value_counts(normalize=True).iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos etc.\n",
        "def estimate_max_admission_proportion_by_etc(etc_list):\n",
        "  if etc_list is None or etc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor max das chances de internação de cada medicamento\n",
        "  return med_adm_prop_by_etc[med_adm_prop_by_etc['etccode'].isin(etc_list)]['admission_proportion_by_etc'].max()\n",
        "\n",
        "X_train['etc_max_adm_prop'] = X_train['etccode'].apply(estimate_max_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_val['etc_max_adm_prop'] = X_val['etccode'].apply(estimate_max_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_test['etc_max_adm_prop'] = X_test['etccode'].apply(estimate_max_admission_proportion_by_etc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos etc.\n",
        "def estimate_mean_admission_proportion_by_etc(etc_list):\n",
        "  if etc_list is None or etc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor mean das chances de internação de cada medicamento\n",
        "  return med_adm_prop_by_etc[med_adm_prop_by_etc['etccode'].isin(etc_list)]['admission_proportion_by_etc'].mean()\n",
        "\n",
        "X_train['etc_mean_adm_prop'] = X_train['etccode'].apply(estimate_mean_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_val['etc_mean_adm_prop'] = X_val['etccode'].apply(estimate_mean_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_test['etc_mean_adm_prop'] = X_test['etccode'].apply(estimate_mean_admission_proportion_by_etc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos etc.\n",
        "def estimate_min_admission_proportion_by_etc(etc_list):\n",
        "  if etc_list is None or etc_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor min das chances de internação de cada medicamento\n",
        "  return med_adm_prop_by_etc[med_adm_prop_by_etc['etccode'].isin(etc_list)]['admission_proportion_by_etc'].min()\n",
        "\n",
        "X_train['etc_min_adm_prop'] = X_train['etccode'].apply(estimate_min_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_val['etc_min_adm_prop'] = X_val['etccode'].apply(estimate_min_admission_proportion_by_etc).fillna(general_admission_proportion)\n",
        "X_test['etc_min_adm_prop'] = X_test['etccode'].apply(estimate_min_admission_proportion_by_etc).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Proporção de admissões por código GSN de medicamentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupar medicamentos por código GSN presentes no dataset de treino e as passagens na emergência\n",
        "med_adm_prop_by_gsn = medrecon_train_df.groupby('gsn')['stay_id'].unique().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular a proporção das passagens na emergência em que havia uso do medicamento com um nome específico e que terminaram em admissão hospitalar\n",
        "med_adm_prop_by_gsn['admission_proportion_by_gsn'] = med_adm_prop_by_gsn['stay_id'].apply(\n",
        "    lambda stay_ids: edstays_df[edstays_df[\"stay_id\"].isin(stay_ids)]['hadm_id'].notna().mean()\n",
        ")\n",
        "# med_adm_prop_by_gsn é a referência para a proporção de admissão relacionada a cada medicamento\n",
        "med_adm_prop_by_gsn.drop(columns=['stay_id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Usar chance de admissão geral dos dados de treino caso não haja medicamentos em uso com código GSN\n",
        "general_admission_proportion = y_train.value_counts(normalize=True).iloc[1]\n",
        "\n",
        "# Definir função que estima chance de internação baseada nos códigos GSN.\n",
        "def estimate_max_admission_proportion_by_gsn(gsn_list):\n",
        "  if gsn_list is None or gsn_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao de maior chance de internação\n",
        "  return med_adm_prop_by_gsn[med_adm_prop_by_gsn['gsn'].isin(gsn_list)]['admission_proportion_by_gsn'].max()\n",
        "\n",
        "X_train['gsn_max_adm_prop'] = X_train['gsn'].apply(estimate_max_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_val['gsn_max_adm_prop'] = X_val['gsn'].apply(estimate_max_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_test['gsn_max_adm_prop'] = X_test['gsn'].apply(estimate_max_admission_proportion_by_gsn).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos GSN.\n",
        "def estimate_mean_admission_proportion_by_gsn(gsn_list):\n",
        "  if gsn_list is None or gsn_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente à média entre as chances de internação\n",
        "  return med_adm_prop_by_gsn[med_adm_prop_by_gsn['gsn'].isin(gsn_list)]['admission_proportion_by_gsn'].mean()\n",
        "\n",
        "X_train['gsn_mean_adm_prop'] = X_train['gsn'].apply(estimate_mean_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_val['gsn_mean_adm_prop'] = X_val['gsn'].apply(estimate_mean_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_test['gsn_mean_adm_prop'] = X_test['gsn'].apply(estimate_mean_admission_proportion_by_gsn).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos GSN.\n",
        "def estimate_min_admission_proportion_by_gsn(gsn_list):\n",
        "  if gsn_list is None or gsn_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor mínimo entre as chances de internação\n",
        "  return med_adm_prop_by_gsn[med_adm_prop_by_gsn['gsn'].isin(gsn_list)]['admission_proportion_by_gsn'].min()\n",
        "\n",
        "X_train['gsn_min_adm_prop'] = X_train['gsn'].apply(estimate_min_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_val['gsn_min_adm_prop'] = X_val['gsn'].apply(estimate_min_admission_proportion_by_gsn).fillna(general_admission_proportion)\n",
        "X_test['gsn_min_adm_prop'] = X_test['gsn'].apply(estimate_min_admission_proportion_by_gsn).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Proporção de admissões por nome de medicamentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agrupar medicamentos por código name presentes no dataset de treino e as passagens na emergência\n",
        "med_adm_prop_by_name = medrecon_train_df.groupby('name')['stay_id'].unique().reset_index()\n",
        "\n",
        "# Calcular a proporção das passagens na emergência em que havia uso do medicamento com um nome específico e que terminaram em admissão hospitalar\n",
        "med_adm_prop_by_name['admission_proportion_by_name'] = med_adm_prop_by_name['stay_id'].apply(\n",
        "    lambda stay_ids: edstays_df[edstays_df[\"stay_id\"].isin(stay_ids)]['hadm_id'].notna().mean()\n",
        ")\n",
        "# med_adm_prop_by_name é a referência para a proporção de admissão relacionada a cada medicamento\n",
        "med_adm_prop_by_name.drop(columns=['stay_id'], inplace=True)\n",
        "\n",
        "# Usar chance de admissão geral dos dados de treino caso não haja medicamentos em uso com código name\n",
        "general_admission_proportion = y_train.value_counts(normalize=True).iloc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos name.\n",
        "def estimate_max_admission_proportion_by_name(name_list):\n",
        "  if name_list is None or name_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor máximo entre as chances de internação de cada nome de medicamento\n",
        "  return med_adm_prop_by_name[med_adm_prop_by_name['name'].isin(name_list)]['admission_proportion_by_name'].max()\n",
        "\n",
        "X_train['med_name_max_adm_prop'] = X_train['name'].apply(estimate_max_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_val['med_name_max_adm_prop'] = X_val['name'].apply(estimate_max_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_test['med_name_max_adm_prop'] = X_test['name'].apply(estimate_max_admission_proportion_by_name).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos name.\n",
        "def estimate_mean_admission_proportion_by_name(name_list):\n",
        "  if name_list is None or name_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor mean entre as chances de internação de cada nome de medicamento\n",
        "  return med_adm_prop_by_name[med_adm_prop_by_name['name'].isin(name_list)]['admission_proportion_by_name'].mean()\n",
        "\n",
        "X_train['med_name_mean_adm_prop'] = X_train['name'].apply(estimate_mean_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_val['med_name_mean_adm_prop'] = X_val['name'].apply(estimate_mean_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_test['med_name_mean_adm_prop'] = X_test['name'].apply(estimate_mean_admission_proportion_by_name).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir função que estima chance de internação baseada nos códigos name.\n",
        "def estimate_min_admission_proportion_by_name(name_list):\n",
        "  if name_list is None or name_list is np.nan:\n",
        "    return general_admission_proportion\n",
        "  # Entre os medicamentos em uso, selecionar o valor correspondente ao valor min entre as chances de internação de cada nome de medicamento\n",
        "  return med_adm_prop_by_name[med_adm_prop_by_name['name'].isin(name_list)]['admission_proportion_by_name'].min()\n",
        "\n",
        "X_train['med_name_min_adm_prop'] = X_train['name'].apply(estimate_min_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_val['med_name_min_adm_prop'] = X_val['name'].apply(estimate_min_admission_proportion_by_name).fillna(general_admission_proportion)\n",
        "X_test['med_name_min_adm_prop'] = X_test['name'].apply(estimate_min_admission_proportion_by_name).fillna(general_admission_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalizar dados numéricos com base nos dados de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar dados numéricos\n",
        "## Selecionar dados numéricos\n",
        "numeric_cols = ['anchor_age','temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'acuity', 'pain', 'etc_min_adm_prop', 'etc_mean_adm_prop', 'etc_max_adm_prop', 'ndc_min_adm_prop', 'ndc_mean_adm_prop', 'ndc_max_adm_prop', 'med_count_by_etccode', 'med_count_by_ndc', 'med_name_min_adm_prop', 'med_name_mean_adm_prop', 'med_name_max_adm_prop', 'gsn_min_adm_prop', 'gsn_mean_adm_prop', 'gsn_max_adm_prop']\n",
        "## Normalização\n",
        "scaler = MinMaxScaler()\n",
        "## Dados de treino\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "## Aplicar o mesmo scaler aos dados de validação e teste\n",
        "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qled1OJGWPxE"
      },
      "source": [
        "#### Eliminar colunas que serão excluídas da análise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onISbimDr93I",
        "outputId": "7af25d3b-dd16-495b-d93a-965c8a4528c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: (344320, 81)\n",
            "Validation set size: (38258, 81)\n",
            "Test set size: (42509, 81)\n"
          ]
        }
      ],
      "source": [
        "# Eliminar colunas que não serão utilizadas na análise\n",
        "cols_to_drop = ['intime','stay_id','subject_id','id','gsn','ndc','etccode','name']\n",
        "datasets = [X_train, X_val, X_test, y_train, y_val, y_test]\n",
        "for dataset in datasets:\n",
        "  dataset.drop(columns=[*cols_to_drop], inplace=True, errors='ignore')\n",
        "\n",
        "print(\"Train set size:\", X_train.shape)\n",
        "print(\"Validation set size:\", X_val.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uppXrT84WWci"
      },
      "source": [
        "#### Realizar substituição de dados faltantes com a média dos dados no dataset de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZsPjbzIbWeM0"
      },
      "outputs": [],
      "source": [
        "# Realizar substuição de dados faltantes com a média dos dados no dataset de treino\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "## Preparar imputer com dados de treino\n",
        "imputer.fit(X_train[cols_with_missing_values])\n",
        "## Aplicar em todos os datasets (treino, validação e teste)\n",
        "X_train[cols_with_missing_values] = imputer.transform(X_train[cols_with_missing_values])\n",
        "X_val[cols_with_missing_values] = imputer.transform(X_val[cols_with_missing_values])\n",
        "X_test[cols_with_missing_values] = imputer.transform(X_test[cols_with_missing_values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 344320 entries, 235356 to 241375\n",
            "Data columns (total 81 columns):\n",
            " #   Column                                          Non-Null Count   Dtype  \n",
            "---  ------                                          --------------   -----  \n",
            " 0   gender_F                                        344320 non-null  bool   \n",
            " 1   gender_M                                        344320 non-null  bool   \n",
            " 2   race_AMERICAN INDIAN/ALASKA NATIVE              344320 non-null  bool   \n",
            " 3   race_ASIAN                                      344320 non-null  bool   \n",
            " 4   race_ASIAN - ASIAN INDIAN                       344320 non-null  bool   \n",
            " 5   race_ASIAN - CHINESE                            344320 non-null  bool   \n",
            " 6   race_ASIAN - KOREAN                             344320 non-null  bool   \n",
            " 7   race_ASIAN - SOUTH EAST ASIAN                   344320 non-null  bool   \n",
            " 8   race_BLACK/AFRICAN                              344320 non-null  bool   \n",
            " 9   race_BLACK/AFRICAN AMERICAN                     344320 non-null  bool   \n",
            " 10  race_BLACK/CAPE VERDEAN                         344320 non-null  bool   \n",
            " 11  race_BLACK/CARIBBEAN ISLAND                     344320 non-null  bool   \n",
            " 12  race_HISPANIC OR LATINO                         344320 non-null  bool   \n",
            " 13  race_HISPANIC/LATINO - CENTRAL AMERICAN         344320 non-null  bool   \n",
            " 14  race_HISPANIC/LATINO - COLUMBIAN                344320 non-null  bool   \n",
            " 15  race_HISPANIC/LATINO - CUBAN                    344320 non-null  bool   \n",
            " 16  race_HISPANIC/LATINO - DOMINICAN                344320 non-null  bool   \n",
            " 17  race_HISPANIC/LATINO - GUATEMALAN               344320 non-null  bool   \n",
            " 18  race_HISPANIC/LATINO - HONDURAN                 344320 non-null  bool   \n",
            " 19  race_HISPANIC/LATINO - MEXICAN                  344320 non-null  bool   \n",
            " 20  race_HISPANIC/LATINO - PUERTO RICAN             344320 non-null  bool   \n",
            " 21  race_HISPANIC/LATINO - SALVADORAN               344320 non-null  bool   \n",
            " 22  race_MULTIPLE RACE/ETHNICITY                    344320 non-null  bool   \n",
            " 23  race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER  344320 non-null  bool   \n",
            " 24  race_OTHER                                      344320 non-null  bool   \n",
            " 25  race_PATIENT DECLINED TO ANSWER                 344320 non-null  bool   \n",
            " 26  race_PORTUGUESE                                 344320 non-null  bool   \n",
            " 27  race_SOUTH AMERICAN                             344320 non-null  bool   \n",
            " 28  race_UNABLE TO OBTAIN                           344320 non-null  bool   \n",
            " 29  race_UNKNOWN                                    344320 non-null  bool   \n",
            " 30  race_WHITE                                      344320 non-null  bool   \n",
            " 31  race_WHITE - BRAZILIAN                          344320 non-null  bool   \n",
            " 32  race_WHITE - EASTERN EUROPEAN                   344320 non-null  bool   \n",
            " 33  race_WHITE - OTHER EUROPEAN                     344320 non-null  bool   \n",
            " 34  race_WHITE - RUSSIAN                            344320 non-null  bool   \n",
            " 35  arrival_transport_AMBULANCE                     344320 non-null  bool   \n",
            " 36  arrival_transport_HELICOPTER                    344320 non-null  bool   \n",
            " 37  arrival_transport_OTHER                         344320 non-null  bool   \n",
            " 38  arrival_transport_UNKNOWN                       344320 non-null  bool   \n",
            " 39  arrival_transport_WALK IN                       344320 non-null  bool   \n",
            " 40  in_day_of_the_week_sin                          344320 non-null  float64\n",
            " 41  in_day_of_the_week_cos                          344320 non-null  float64\n",
            " 42  in_hour_of_the_day_sin                          344320 non-null  float64\n",
            " 43  in_hour_of_the_day_cos                          344320 non-null  float64\n",
            " 44  in_month_of_the_year_sin                        344320 non-null  float64\n",
            " 45  in_month_of_the_year_cos                        344320 non-null  float64\n",
            " 46  temperature                                     344320 non-null  float64\n",
            " 47  heartrate                                       344320 non-null  float64\n",
            " 48  resprate                                        344320 non-null  float64\n",
            " 49  o2sat                                           344320 non-null  float64\n",
            " 50  sbp                                             344320 non-null  float64\n",
            " 51  dbp                                             344320 non-null  float64\n",
            " 52  acuity                                          344320 non-null  float64\n",
            " 53  pain                                            344320 non-null  float64\n",
            " 54  anchor_age                                      344320 non-null  float64\n",
            " 55  temperature_is_missing                          344320 non-null  int64  \n",
            " 56  heartrate_is_missing                            344320 non-null  int64  \n",
            " 57  resprate_is_missing                             344320 non-null  int64  \n",
            " 58  o2sat_is_missing                                344320 non-null  int64  \n",
            " 59  sbp_is_missing                                  344320 non-null  int64  \n",
            " 60  dbp_is_missing                                  344320 non-null  int64  \n",
            " 61  acuity_is_missing                               344320 non-null  int64  \n",
            " 62  pain_is_missing                                 344320 non-null  int64  \n",
            " 63  anchor_age_is_missing                           344320 non-null  int64  \n",
            " 64  med_count_by_ndc                                344320 non-null  float64\n",
            " 65  med_count_by_etccode                            344320 non-null  float64\n",
            " 66  med_count_by_name                               344320 non-null  int64  \n",
            " 67  med_count_by_gsn                                344320 non-null  int64  \n",
            " 68  use_no_medication                               344320 non-null  bool   \n",
            " 69  ndc_max_adm_prop                                344320 non-null  float64\n",
            " 70  ndc_mean_adm_prop                               344320 non-null  float64\n",
            " 71  ndc_min_adm_prop                                344320 non-null  float64\n",
            " 72  etc_max_adm_prop                                344320 non-null  float64\n",
            " 73  etc_mean_adm_prop                               344320 non-null  float64\n",
            " 74  etc_min_adm_prop                                344320 non-null  float64\n",
            " 75  gsn_max_adm_prop                                344320 non-null  float64\n",
            " 76  gsn_mean_adm_prop                               344320 non-null  float64\n",
            " 77  gsn_min_adm_prop                                344320 non-null  float64\n",
            " 78  med_name_max_adm_prop                           344320 non-null  float64\n",
            " 79  med_name_mean_adm_prop                          344320 non-null  float64\n",
            " 80  med_name_min_adm_prop                           344320 non-null  float64\n",
            "dtypes: bool(41), float64(29), int64(11)\n",
            "memory usage: 121.2 MB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR_o0DjeWo_S"
      },
      "source": [
        "## Treinar primeiros modelos e avaliar com dataset de validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi9lPpCBWwWU"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "AyghfwdIxO_A",
        "outputId": "abccabdb-caf5-4d39-fe43-eb6c3531eac2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=400, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=400, random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=400, random_state=42)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a RandomForestClassifier object\n",
        "model = RandomForestClassifier(\n",
        "    random_state=42,  # Set random_state for reproducibility\n",
        "    n_estimators=400\n",
        ")\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asNlmWk6xhzU",
        "outputId": "f41465d5-7479-4f11-f315-511eae9f6758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8222197506347865\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Predict probabilities for the validation set\n",
        "y_pred_proba = model.predict_proba(X_val)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "# Calculate AUC\n",
        "auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "print(\"AUC:\", auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0wBN9lIWzWl"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-2yU_aRPyMHv"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Assuming X_train, y_train are your training data and labels\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "# Set parameters (you'll need to tune these)\n",
        "param = {\n",
        "    'objective': 'binary:logistic',  # For binary classification\n",
        "    'eval_metric': 'auc',\n",
        "    'max_depth': 3,\n",
        "    'eta': 0.2,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "num_round = 1000  # Number of boosting rounds\n",
        "model = xgb.train(param, dtrain, num_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsQenYxIyVcc",
        "outputId": "805ed9c0-b88d-4ae1-9c54-56fedba57f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC: 0.8210867664085449\n"
          ]
        }
      ],
      "source": [
        "# Assuming X_val, y_val are your validation data and labels\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_pred_proba = model.predict(dval)\n",
        "\n",
        "# Calculate AUC\n",
        "auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "print(\"AUC:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeozUAl2oSLG",
        "outputId": "1a818822-e7a0-4109-d1fa-a1e2558b98b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=3, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.7; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.7; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.8; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.2, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.7; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7, eta=0.3, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.9; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.8, eta=0.3, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=5, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.1, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.2, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.7; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.8; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=3, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.7; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.8; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.9; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=5, subsample=0.9; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.7; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.8; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.9; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.9, eta=0.3, max_depth=7, subsample=0.9; total time=   0.6s\n",
            "Best parameters: {'colsample_bytree': 0.7, 'eta': 0.2, 'max_depth': 7, 'subsample': 0.9}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'eta': [0.1, 0.2, 0.3],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc'),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='roc_auc',\n",
        "                           cv=3,  # Number of cross-validation folds\n",
        "                           verbose=2)\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgY_IuVbxL6F",
        "outputId": "771b5bda-f37f-4569-ff9f-e7cccccc393a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test AUC: 0.8203943279662188\n"
          ]
        }
      ],
      "source": [
        "# Predict probabilities for the test set using the best model\n",
        "y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Calculate AUC on the test set\n",
        "auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "print(\"Test AUC:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFMeMX3jBntg",
        "outputId": "6a4635e6-8eaf-48ca-a510-deb985abe3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best set of hyperparameters:  {'learning_rate': np.float64(0.08057545948216362), 'max_depth': 9, 'n_estimators': 162, 'subsample': np.float64(0.8856221455197644)}\n",
            "Best score:  0.8461416893458009\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define the hyperparameter distributions\n",
        "param_dist = {\n",
        "    'max_depth': stats.randint(3, 10),\n",
        "    'learning_rate': stats.uniform(0.01, 0.1),\n",
        "    'subsample': stats.uniform(0.5, 0.5),\n",
        "    'n_estimators':stats.randint(50, 200)\n",
        "}\n",
        "\n",
        "# Create the XGBoost model object\n",
        "xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
        "print(\"Best score: \", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define the hyperparameter distributions\n",
        "param_dist = {\n",
        "    'max_depth': stats.randint(6, 30),\n",
        "    'learning_rate': stats.uniform(0.01, 0.1),\n",
        "    'subsample': stats.uniform(0.5, 0.5),\n",
        "    'n_estimators':stats.randint(400, 800)\n",
        "}\n",
        "\n",
        "# Create the XGBoost model object\n",
        "xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
        "\n",
        "# Create the RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit the RandomizedSearchCV object to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best set of hyperparameters and the corresponding score\n",
        "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
        "print(\"Best score: \", random_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### XGBoost hyperparameters\n",
        "\n",
        "Best set of hyperparameters:  {'learning_rate': np.float64(0.08057545948216362), 'max_depth': 9, 'n_estimators': 162, 'subsample': np.float64(0.8856221455197644)}\n",
        "\n",
        "Best score:  0.8461416893458009\n",
        "\n",
        "---\n",
        "\n",
        "Best set of hyperparameters:  {'learning_rate': np.float64(0.03682064960174636), 'max_depth': 11, 'n_estimators': 374, 'subsample': np.float64(0.9099935577581488)}\n",
        "\n",
        "Best score:  0.8465467772144158\n",
        "\n",
        "---\n",
        "\n",
        "Best set of hyperparameters:  {'learning_rate': np.float64(0.028847877325705033), 'max_depth': 11, 'n_estimators': 476, 'subsample': np.float64(0.908755289935228)}\n",
        "\n",
        "Best score:  0.8468310267107876\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "out0RNiclRs8",
        "outputId": "db4dd7e9-aab7-467b-b4b7-1094de034afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:40<00:00,  2.00s/trial, best loss: -0.821987666465536] \n",
            "Best hyperparameters: {'colsample_bytree': np.float64(0.8172142575101772), 'eta': np.float64(0.03588580696508417), 'max_depth': np.int64(5), 'subsample': np.float64(0.8320331706857366)}\n"
          ]
        }
      ],
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "import xgboost as xgb\n",
        "\n",
        "# Define the objective function to minimize\n",
        "def objective(params):\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "    model = xgb.train(params, dtrain, num_boost_round=1000,\n",
        "                      early_stopping_rounds=10, evals=[(dval, 'eval')], verbose_eval=False)\n",
        "\n",
        "    y_pred_proba = model.predict(dval)\n",
        "    auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "    return {'loss': -auc, 'status': STATUS_OK}\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "space = {\n",
        "    'max_depth': hp.choice('max_depth', range(3, 10)),\n",
        "    'eta': hp.uniform('eta', 0.01, 0.3),\n",
        "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc'\n",
        "}\n",
        "\n",
        "# Initialize trials object to track results\n",
        "trials = Trials()\n",
        "\n",
        "# Run hyperparameter optimization\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=50,  # Number of evaluations\n",
        "            trials=trials)\n",
        "\n",
        "print(\"Best hyperparameters:\", best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVwRzsmPPcW8",
        "outputId": "411cb217-3498-4145-d5f1-00d6587a933a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test AUC with best hyperparameters: 0.8231851611233246\n"
          ]
        }
      ],
      "source": [
        "# Train the final model with best hyperparameters\n",
        "best_model = xgb.train(best, xgb.DMatrix(X_train, label=y_train), num_boost_round=1000)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "dval = xgb.DMatrix(X_val)\n",
        "y_pred_proba = best_model.predict(dval)\n",
        "\n",
        "# Calculate AUC on the test set\n",
        "test_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "\n",
        "print(\"Test AUC with best hyperparameters:\", test_auc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
