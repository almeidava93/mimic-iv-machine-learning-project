mimic_admission_classifier_001:
  description: "one linear layer, after two linear layers + skip connection, final classification layer."
  dropout: 0.5
  n_epochs: 20
  max_val_auc: 0.8315
  model_schema: >
    MimicAdmissionClassifier(
    (dropout): Dropout(p=0.5, inplace=False)
    (layers_1): Sequential(
      (0): Linear(in_features=67, out_features=256, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
    )
    (layers_2): Sequential(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
    )
    (layers_3): Sequential(
      (0): Linear(in_features=256, out_features=1, bias=True)
      (1): Sigmoid()
    )
    )

mimic_admission_classifier_002:
  description: "classic MLP, four linear layers"
  dropout: 0.5
  n_epochs: 40
  max_val_auc: 0.8305
  model_schema: >
    MimicAdmissionClassifier(
    (dropout): Dropout(p=0.5, inplace=False)
    (mlp): Sequential(
      (0): Linear(in_features=67, out_features=128, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=128, out_features=128, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Dropout(p=0.5, inplace=False)
      (9): Linear(in_features=128, out_features=1, bias=True)
      (10): Sigmoid()
    )
 